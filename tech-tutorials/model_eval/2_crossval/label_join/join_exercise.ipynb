{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features, Labels, Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple static feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gender_feature(filename='gender_female.csv'):\n",
    "    \"\"\" Reads in a CSV, drops NAs, returns the DataFrame. \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(filename)\n",
    "    df = df.dropna(how='any')\n",
    "    \n",
    "    return df.set_index('entity_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender_female</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entity_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           gender_female\n",
       "entity_id               \n",
       "309                  1.0\n",
       "324                  1.0\n",
       "48                   1.0\n",
       "210                  0.0\n",
       "180                  1.0"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_gender = gender_feature()\n",
    "my_gender.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A temporal feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def incident_aggregation(as_of_date, agg_col, date_col, time_delta, \n",
    "                         agg_funcs, filename='incidents.csv'):\n",
    "    \"\"\"\n",
    "    Reads and aggregates a CSV file over a date range.\n",
    "    \n",
    "    Args:\n",
    "        as_of_date (datetime): End of the aggregation window (excluded).\n",
    "        agg_col (str): Name of the column for aggregation.\n",
    "        date_col (str): Name of the column that gives knowledge dates for \n",
    "                        the values in agg_col.\n",
    "        time_delta (pd.Timedelta): Time range. Gives the time \n",
    "                                   window preceding the as_of_date over\n",
    "                                   which we aggregate.\n",
    "        agg_funcs (dict): A dictionary that maps column names to functions.\n",
    "                          The functions will be applied to the groupby, \n",
    "                          and the resulting dataframe contains columns\n",
    "                          named like <key>_<timedelta>.\n",
    "        filename (str): Path to the CSV that should be aggregated. The \n",
    "                       CSV must contain an entity_id column, as well as \n",
    "                       the columns given by agg_col and date_col.\n",
    "        \n",
    "    Returns (pd.DataFrame): A dataframe, uniquely indexed by entity_id,\n",
    "                            with columns that contain the aggregations\n",
    "                            from agg_funcs. \n",
    "    \"\"\"\n",
    "    \n",
    "    # read the CSV\n",
    "    df = pd.read_csv(filename)\n",
    "    df[date_col] = pd.to_datetime(df[date_col])\n",
    "    \n",
    "    # restrict to data in aggregation window\n",
    "    df = df.loc[df[date_col] < as_of_date,:]\n",
    "    df = df.loc[df[date_col] >= (as_of_date-time_delta),:]\n",
    "    \n",
    "    # add as_of_date to the index\n",
    "    df['as_of_date'] = as_of_date\n",
    "    df = df.set_index(['entity_id','as_of_date'])\n",
    "    \n",
    "    # just some formatting for naming the columns\n",
    "    nice_timedelta_str = str(time_delta).replace('00:00:00','').replace(' ','')\n",
    "    agg_funcs = {k+'_'+nice_timedelta_str: v for k,v in agg_funcs.items()}\n",
    "    \n",
    "    # aggregate by entity_id and apply the functions\n",
    "    return df[agg_col].groupby(level=[0,1]).agg(agg_funcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_agg = incident_aggregation(pd.to_datetime('2016-01-01'),\n",
    "                             'incident_type',\n",
    "                             'incident_date',\n",
    "                              pd.Timedelta(365,'d'), \n",
    "                              {'count_neglects': lambda x: sum(x=='neglect_of_duty'),\n",
    "                              'count_conduct': lambda x: sum(x=='conduct_unbecoming')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count_conduct_365days</th>\n",
       "      <th>count_neglects_365days</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entity_id</th>\n",
       "      <th>as_of_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      count_conduct_365days  count_neglects_365days\n",
       "entity_id as_of_date                                               \n",
       "0         2016-01-01                      2                       1\n",
       "1         2016-01-01                      2                       1\n",
       "2         2016-01-01                      1                       0\n",
       "3         2016-01-01                      1                       2\n",
       "4         2016-01-01                      3                       0"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_agg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def label_aggregation(as_of_date, time_delta, filename='incidents.csv'):\n",
    "    \"\"\" Find if an entity has a 'discipline' or 'conduct_unbecoming' incident\n",
    "        that is decided as sustained.\n",
    "    Args:\n",
    "        as_of_date (datetime): Beginning of the aggregation window (included).\n",
    "        time_delta (pd.Timedelta): Time range. Gives the time \n",
    "                                   window following the as_of_date over\n",
    "                                   which we aggregate.\n",
    "        filename (str): Path to the incidents CSV, which contains\n",
    "                        entity_id, incident type and date, and \n",
    "                        decision with date.\n",
    "    Returns (pd.Series):\n",
    "        A boolean series, indexed uniquely by entity_id and as_of_date,\n",
    "        giving if the entity had at least one sustained disciplinary\n",
    "        or conduct_unbecoming event that fell within the time window.\n",
    "    \"\"\"\n",
    "    \n",
    "    # load the CSV\n",
    "    df = pd.read_csv(filename, parse_dates=['incident_date','decision_date'])\n",
    "        \n",
    "    # restrict to incidents after the as_of_date\n",
    "    df = df.loc[df.incident_date>=as_of_date,:]\n",
    "    \n",
    "    # restrict to decisions in the time window\n",
    "    df = df.loc[df.decision_date<(as_of_date+time_delta),:]\n",
    "\n",
    "    # add the as_of_date to the index\n",
    "    df['as_of_date'] = as_of_date\n",
    "    df = df.set_index(['entity_id','as_of_date'])\n",
    "    \n",
    "    # binarize\n",
    "    df['adverse_incident'] = df.incident_type.isin(['discipline','conduct_unbecoming'])\\\n",
    "                             &(df.decision=='sustained')\n",
    "    \n",
    "    # aggregate and return\n",
    "    return df.adverse_incident.groupby(level=[0,1]).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_labels = label_aggregation(pd.to_datetime('2016-01-01'), pd.Timedelta(90,'d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "entity_id  as_of_date\n",
       "2          2016-01-01     True\n",
       "3          2016-01-01    False\n",
       "8          2016-01-01    False\n",
       "9          2016-01-01    False\n",
       "10         2016-01-01    False\n",
       "Name: adverse_incident, dtype: bool"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining Labels and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_gender['as_of_date'] = pd.to_datetime('2016-01-01')\n",
    "my_gender = my_gender.set_index(['as_of_date'], append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>adverse_incident</th>\n",
       "      <th>gender_female</th>\n",
       "      <th>count_conduct_365days</th>\n",
       "      <th>count_neglects_365days</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entity_id</th>\n",
       "      <th>as_of_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     adverse_incident  gender_female  count_conduct_365days  \\\n",
       "entity_id as_of_date                                                          \n",
       "2         2016-01-01             True            0.0                    1.0   \n",
       "3         2016-01-01            False            0.0                    1.0   \n",
       "8         2016-01-01            False            1.0                    3.0   \n",
       "9         2016-01-01            False            0.0                    1.0   \n",
       "10        2016-01-01            False            0.0                    1.0   \n",
       "\n",
       "                      count_neglects_365days  \n",
       "entity_id as_of_date                          \n",
       "2         2016-01-01                     0.0  \n",
       "3         2016-01-01                     2.0  \n",
       "8         2016-01-01                     2.0  \n",
       "9         2016-01-01                     0.0  \n",
       "10        2016-01-01                     2.0  "
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = my_labels.to_frame().join(my_gender, how='left')\\\n",
    "                              .join(my_agg, how='left')\n",
    "    \n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## But clearly, some entities are missing...\n",
    "Make a table of 'active' entities for the given date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def active_officers(as_of_date, filename='patrol_duty.csv'):\n",
    "    \"\"\"Check if an officer is on patrol duty for the as_of_date.\"\"\"\n",
    "    \n",
    "    # read CSV\n",
    "    df = pd.read_csv(filename, parse_dates=['start_date','end_date'])\n",
    "    \n",
    "    # check if as_of_date falls between start and end date of duty\n",
    "    df['active'] = (df.start_date<=as_of_date)&(df.end_date>=as_of_date)\n",
    "    \n",
    "    df['as_of_date'] = as_of_date\n",
    "    df = df.set_index(['entity_id','as_of_date'])\n",
    "    \n",
    "    return df[df.active==True].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_active = active_officers(pd.to_datetime('2016-01-01'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now index into the dataset with our new entity list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>adverse_incident</th>\n",
       "      <th>gender_female</th>\n",
       "      <th>count_conduct_365days</th>\n",
       "      <th>count_neglects_365days</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entity_id</th>\n",
       "      <th>as_of_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     adverse_incident  gender_female  count_conduct_365days  \\\n",
       "entity_id as_of_date                                                          \n",
       "0         2016-01-01              NaN            NaN                    NaN   \n",
       "2         2016-01-01             True            0.0                    1.0   \n",
       "3         2016-01-01            False            0.0                    1.0   \n",
       "13        2016-01-01              NaN            NaN                    NaN   \n",
       "15        2016-01-01              NaN            NaN                    NaN   \n",
       "\n",
       "                      count_neglects_365days  \n",
       "entity_id as_of_date                          \n",
       "0         2016-01-01                     NaN  \n",
       "2         2016-01-01                     0.0  \n",
       "3         2016-01-01                     2.0  \n",
       "13        2016-01-01                     NaN  \n",
       "15        2016-01-01                     NaN  "
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.loc[my_active,:].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to coalesce / impute!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: \n",
    "- write a better label fetcher that takes several as-of-dates and returns \n",
    "  one DF with all the data\n",
    "- create an aux that has additional information\n",
    "- write a split creator that takes as [(as_of_date, usefor)], an active_status generating \n",
    "  function, a label generating function, and a list of feature generating functions (that accept\n",
    "  kwargs), and kwargs for the feature generators. Returns a X_train, X_test, y_train, y_test, after checking if anything has too many NaNas\n",
    "- update the gender feature to have as of date in the index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A slightly nicer label fetcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def label_aggregation(as_of_dates, time_delta, filename='incidents.csv'):\n",
    "    \"\"\" Find if an entity has a 'discipline' or 'conduct_unbecoming' incident\n",
    "        that is decided as sustained.\n",
    "    Args:\n",
    "        as_of_dates ([datetime]): List of beginnings of the aggregation \n",
    "                                  windows (included).\n",
    "        time_delta (pd.Timedelta): Time range. Gives the time \n",
    "                                   window following the as_of_date over\n",
    "                                   which we aggregate.\n",
    "        filename (str): Path to the incidents CSV, which contains\n",
    "                        entity_id, incident type and date, and \n",
    "                        decision with date.\n",
    "    Returns (pd.Series):\n",
    "        A boolean series, indexed uniquely by entity_id and as_of_date,\n",
    "        giving if the entity had at least one sustained disciplinary\n",
    "        or conduct_unbecoming event that fell within the time window.\n",
    "    \"\"\"\n",
    "    \n",
    "    # load the CSV\n",
    "    df = pd.read_csv(filename, parse_dates=['incident_date','decision_date'])\n",
    "    \n",
    "    if len(set(as_of_dates))!=len(as_of_dates):\n",
    "        raise ValueError(\"As of dates need to be unique!\")\n",
    "        \n",
    "    as_of_dates = sorted(as_of_dates)\n",
    "    \n",
    "    # let's be cautious here already and do a sanity check\n",
    "    for idx, aod in enumerate(as_of_dates[:-1]):\n",
    "        if aod+time_delta >= as_of_dates[idx+1]:\n",
    "            warnings.warn(\"Your label windows will overlap!\")\n",
    "        \n",
    "    dfs = []\n",
    "    \n",
    "    # go over all the dates\n",
    "    for as_of_date in as_of_dates:\n",
    "        \n",
    "        # restrict to incidents after the as_of_date\n",
    "        this_df = df.loc[df.incident_date>=as_of_date,:]\n",
    "\n",
    "        # restrict to decisions in the time window\n",
    "        this_df = this_df.loc[this_df.decision_date<(as_of_date+time_delta),:]\n",
    "\n",
    "        # add the as_of_date to the index\n",
    "        this_df['as_of_date'] = as_of_date\n",
    "        this_df = this_df.set_index(['entity_id','as_of_date'])\n",
    "\n",
    "        # binarize\n",
    "        this_df['adverse_incident'] = this_df.incident_type.isin(['discipline','conduct_unbecoming'])\\\n",
    "                                      &(this_df.decision=='sustained')\n",
    "            \n",
    "        dfs.append(this_df.adverse_incident.groupby(level=[0,1]).max())\n",
    "    \n",
    "    # concat and return\n",
    "    return pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_labels = label_aggregation([pd.to_datetime('2016-01-01'),\n",
    "                               pd.to_datetime('2016-05-01')],\n",
    "                              pd.Timedelta(90,'d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "entity_id  as_of_date\n",
       "2          2016-01-01     True\n",
       "3          2016-01-01    False\n",
       "8          2016-01-01    False\n",
       "9          2016-01-01    False\n",
       "10         2016-01-01    False\n",
       "Name: adverse_incident, dtype: bool"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2016-01-01', '2016-05-01'], dtype='datetime64[ns]', name='as_of_date', freq=None)"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_labels.index.levels[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ... and slightly nicer active-officer fetcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def active_officers(as_of_dates, filename='patrol_duty.csv'):\n",
    "    \"\"\"Check if an officer is on patrol duty for the as_of_date.\"\"\"\n",
    "    \n",
    "    # read CSV\n",
    "    df = pd.read_csv(filename, parse_dates=['start_date','end_date'])\n",
    "    \n",
    "    indices = []\n",
    "    \n",
    "    for as_of_date in as_of_dates:\n",
    "\n",
    "        # check if as_of_date falls between start and end date of duty\n",
    "        this_active = (df.start_date<=as_of_date)&(df.end_date>=as_of_date)\n",
    "\n",
    "        df['as_of_date'] = as_of_date\n",
    "        \n",
    "        indices.append(df.set_index(['entity_id','as_of_date']).index)\n",
    "    \n",
    "    return pd.concat(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate a non-NDFrame object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-360-dc169966c691>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m my_active = active_officers([pd.to_datetime('2016-01-01'),\n\u001b[1;32m----> 2\u001b[1;33m                              pd.to_datetime('2016-05-01')])\n\u001b[0m",
      "\u001b[1;32m<ipython-input-359-0391eb456679>\u001b[0m in \u001b[0;36mactive_officers\u001b[1;34m(as_of_dates, filename)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mindices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'entity_id'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'as_of_date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/bene/DSaPP/env35/lib/python3.5/site-packages/pandas/tools/merge.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, copy)\u001b[0m\n\u001b[0;32m    843\u001b[0m                        \u001b[0mkeys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    844\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 845\u001b[1;33m                        copy=copy)\n\u001b[0m\u001b[0;32m    846\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    847\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/bene/DSaPP/env35/lib/python3.5/site-packages/pandas/tools/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity, copy)\u001b[0m\n\u001b[0;32m    899\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mobjs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    900\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNDFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 901\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cannot concatenate a non-NDFrame object\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    902\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    903\u001b[0m             \u001b[1;31m# consolidate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot concatenate a non-NDFrame object"
     ]
    }
   ],
   "source": [
    "my_active = active_officers([pd.to_datetime('2016-01-01'),\n",
    "                             pd.to_datetime('2016-05-01')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the Split!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_splitter(split_dates, label_time_delta, label_fetcher, feature_fetchers):\n",
    "    \n",
    "    test_as_of_dates = [aod for aod, usefor in split_dates if usefor=='test']\n",
    "    train_as_of_dates = [aod for aod, usefor in split_dates if usefor=='train']\n",
    "    \n",
    "    print(test_as_of_dates)\n",
    "    print(train_as_of_dates)\n",
    "    \n",
    "    # check that the train/test splits are well-separated\n",
    "    if max(train_as_of_dates) + label_time_delta >= min(test_as_of_dates):\n",
    "        raise ValueError(\"Your train and test label windows overlap!\")\n",
    "        \n",
    "    # fetch the index of active officers\n",
    "    actives = \n",
    "        \n",
    "    # fetch the DF with labels\n",
    "    labels = label_aggregation(list(zip(*split_dates))[0], label_time_delta)\n",
    "    \n",
    "    print(labels.head())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Timestamp('2016-08-01 00:00:00')]\n",
      "[Timestamp('2016-01-01 00:00:00'), Timestamp('2016-04-30 00:00:00')]\n",
      "entity_id  as_of_date\n",
      "2          2016-01-01     True\n",
      "3          2016-01-01    False\n",
      "8          2016-01-01    False\n",
      "9          2016-01-01    False\n",
      "10         2016-01-01    False\n",
      "Name: adverse_incident, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "train_test_splitter([(pd.to_datetime('2016-01-01'), 'train'), \n",
    "                     (pd.to_datetime('2016-04-30') , 'train'), \n",
    "                      (pd.to_datetime('2016-08-01'), 'test')],\n",
    "                    pd.Timedelta(90, 'd'),\n",
    "                    2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2016-01-01 00:00:00'),\n",
       " Timestamp('2016-03-01 00:00:00'),\n",
       " Timestamp('2016-05-01 00:00:00'))"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(*[(pd.to_datetime('2016-01-01'), 'train'), \n",
    "                     (pd.to_datetime('2016-03-01') , 'train'), \n",
    "                      (pd.to_datetime('2016-05-01'), 'test')]))[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
